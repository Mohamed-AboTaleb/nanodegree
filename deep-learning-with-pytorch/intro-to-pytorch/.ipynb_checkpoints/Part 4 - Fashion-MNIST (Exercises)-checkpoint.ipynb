{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "Now it's your turn to build and train a neural network. You'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n",
    "\n",
    "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "In this notebook, you'll build your own neural network. For the most part, you could just copy and paste the code from Part 3, but you wouldn't be learning. It's important for you to write the code yourself and get it to work. Feel free to consult the previous notebooks though as you work through this.\n",
    "\n",
    "First off, let's load the dataset through torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████▉| 26419200/26421880 [02:57<00:00, 165138.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\\train-images-idx3-ubyte.gz to C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|                                                         | 0/29515 [00:02<?, ?it/s]\n",
      " 28%|███████████▉                               | 8192/29515 [00:02<00:00, 40156.82it/s]\n",
      " 56%|███████████████████████▎                  | 16384/29515 [00:02<00:00, 39169.77it/s]\n",
      " 83%|██████████████████████████████████▉       | 24576/29515 [00:02<00:00, 42025.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "  0%|                                                       | 0/4422102 [00:01<?, ?it/s]\n",
      "\n",
      "  0%|                                         | 8192/4422102 [00:01<03:30, 20922.57it/s]\n",
      "\n",
      "  0%|▏                                       | 16384/4422102 [00:01<03:14, 22705.78it/s]\n",
      "\n",
      "  1%|▎                                       | 32768/4422102 [00:01<02:24, 30326.12it/s]\n",
      "\n",
      "  1%|▍                                       | 49152/4422102 [00:02<01:57, 37283.32it/s]\n",
      "\n",
      "  2%|▋                                       | 73728/4422102 [00:02<01:43, 42181.72it/s]\n",
      "\n",
      "  3%|█                                      | 114688/4422102 [00:02<01:22, 51968.80it/s]\n",
      "\n",
      "  4%|█▎                                     | 155648/4422102 [00:03<01:05, 65234.07it/s]\n",
      "\n",
      "  4%|█▋                                     | 196608/4422102 [00:03<00:51, 81875.42it/s]\n",
      "\n",
      "  5%|█▉                                     | 221184/4422102 [00:03<00:43, 97659.33it/s]\n",
      "\n",
      "  5%|██                                     | 237568/4422102 [00:03<00:50, 82724.88it/s]\n",
      "\n",
      "  6%|██▍                                   | 278528/4422102 [00:03<00:41, 100256.04it/s]\n",
      "\n",
      "  7%|██▋                                   | 319488/4422102 [00:04<00:34, 118148.33it/s]\n",
      "\n",
      "  8%|███                                   | 360448/4422102 [00:04<00:30, 132374.34it/s]\n",
      "\n",
      "  9%|███▍                                  | 401408/4422102 [00:04<00:26, 151030.18it/s]\n",
      "\n",
      " 10%|███▊                                  | 442368/4422102 [00:04<00:24, 163254.33it/s]\n",
      "\n",
      " 11%|████▏                                 | 483328/4422102 [00:04<00:22, 172672.78it/s]\n",
      "\n",
      " 12%|████▌                                 | 524288/4422102 [00:05<00:27, 141456.09it/s]\n",
      "\n",
      " 13%|████▊                                 | 565248/4422102 [00:05<00:24, 155254.56it/s]\n",
      "\n",
      " 14%|█████▏                                | 606208/4422102 [00:05<00:27, 140603.83it/s]\n",
      "\n",
      " 15%|█████▌                                | 647168/4422102 [00:06<00:29, 126779.32it/s]\n",
      "\n",
      " 16%|█████▉                                | 696320/4422102 [00:06<00:26, 139234.44it/s]\n",
      "\n",
      " 17%|██████▎                               | 737280/4422102 [00:06<00:23, 153673.54it/s]\n",
      "\n",
      " 17%|██████▌                               | 770048/4422102 [00:06<00:23, 156209.02it/s]\n",
      "\n",
      " 18%|██████▉                               | 811008/4422102 [00:07<00:21, 167414.96it/s]\n",
      "\n",
      " 19%|███████▏                              | 835584/4422102 [00:07<00:22, 158115.69it/s]\n",
      "\n",
      " 19%|███████▍                              | 860160/4422102 [00:07<00:25, 137782.97it/s]\n",
      "\n",
      " 20%|███████▌                              | 876544/4422102 [00:07<00:26, 135564.50it/s]\n",
      "\n",
      " 21%|████████                              | 942080/4422102 [00:07<00:22, 155088.57it/s]\n",
      "\n",
      " 22%|████████▍                             | 983040/4422102 [00:08<00:20, 166674.86it/s]\n",
      "\n",
      " 23%|████████▌                            | 1024000/4422102 [00:08<00:19, 175561.16it/s]\n",
      "\n",
      " 24%|████████▊                            | 1048576/4422102 [00:08<00:18, 182879.21it/s]\n",
      "\n",
      " 25%|█████████▎                           | 1105920/4422102 [00:08<00:21, 156102.46it/s]\n",
      "\n",
      " 26%|█████████▌                           | 1146880/4422102 [00:09<00:19, 165697.36it/s]\n",
      "\n",
      " 26%|█████████▊                           | 1171456/4422102 [00:09<00:21, 148025.37it/s]\n",
      "\n",
      "26427392it [03:10, 165138.53it/s]                                                       \n",
      "\n",
      " 27%|██████████▏                          | 1212416/4422102 [00:09<00:28, 113867.32it/s]\n",
      "\n",
      " 28%|██████████▎                          | 1236992/4422102 [00:10<00:27, 116054.37it/s]\n",
      "\n",
      " 29%|██████████▋                          | 1277952/4422102 [00:10<00:27, 112319.48it/s]\n",
      "\n",
      " 30%|███████████                          | 1318912/4422102 [00:10<00:24, 127582.23it/s]\n",
      "\n",
      " 31%|███████████▍                         | 1359872/4422102 [00:10<00:21, 143093.96it/s]\n",
      "\n",
      " 32%|███████████▋                         | 1400832/4422102 [00:11<00:19, 157696.99it/s]\n",
      "\n",
      " 33%|████████████                         | 1441792/4422102 [00:11<00:19, 154214.48it/s]\n",
      "\n",
      " 34%|████████████▍                        | 1482752/4422102 [00:11<00:16, 182582.30it/s]\n",
      "\n",
      " 34%|████████████▋                        | 1523712/4422102 [00:11<00:15, 182548.45it/s]\n",
      "\n",
      " 35%|█████████████                        | 1564672/4422102 [00:12<00:19, 149897.87it/s]\n",
      "\n",
      " 36%|█████████████▍                       | 1605632/4422102 [00:12<00:17, 162482.05it/s]\n",
      "\n",
      " 37%|█████████████▊                       | 1646592/4422102 [00:12<00:17, 161596.99it/s]\n",
      "\n",
      " 38%|██████████████                       | 1687552/4422102 [00:12<00:18, 150530.07it/s]\n",
      "\n",
      " 39%|██████████████▍                      | 1728512/4422102 [00:12<00:14, 185231.91it/s]\n",
      "\n",
      " 40%|██████████████▋                      | 1761280/4422102 [00:13<00:14, 180628.92it/s]\n",
      "\n",
      " 41%|███████████████                      | 1802240/4422102 [00:13<00:12, 202219.98it/s]\n",
      "\n",
      " 42%|███████████████▍                     | 1843200/4422102 [00:13<00:15, 166623.86it/s]\n",
      "\n",
      " 43%|███████████████▊                     | 1884160/4422102 [00:13<00:15, 163444.99it/s]\n",
      "\n",
      " 43%|███████████████▉                     | 1908736/4422102 [00:14<00:15, 162936.78it/s]\n",
      "\n",
      " 44%|████████████████▏                    | 1933312/4422102 [00:14<00:16, 152355.73it/s]\n",
      "\n",
      " 44%|████████████████▍                    | 1966080/4422102 [00:14<00:17, 141004.36it/s]\n",
      "\n",
      " 45%|████████████████▊                    | 2007040/4422102 [00:14<00:17, 138667.03it/s]\n",
      "\n",
      " 46%|█████████████████▏                   | 2048000/4422102 [00:14<00:14, 163670.37it/s]\n",
      "\n",
      " 47%|█████████████████▍                   | 2088960/4422102 [00:15<00:12, 184280.13it/s]\n",
      "\n",
      " 48%|█████████████████▋                   | 2113536/4422102 [00:15<00:14, 157361.92it/s]\n",
      "\n",
      " 48%|█████████████████▉                   | 2138112/4422102 [00:15<00:21, 107012.43it/s]\n",
      "\n",
      " 49%|██████████████████▏                  | 2179072/4422102 [00:15<00:17, 124653.57it/s]\n",
      "\n",
      " 50%|██████████████████▍                  | 2203648/4422102 [00:16<00:15, 142128.17it/s]\n",
      "\n",
      " 51%|██████████████████▋                  | 2236416/4422102 [00:16<00:16, 131721.98it/s]\n",
      "\n",
      " 51%|██████████████████▉                  | 2260992/4422102 [00:16<00:16, 128269.09it/s]\n",
      "\n",
      " 51%|███████████████████                  | 2277376/4422102 [00:16<00:19, 108804.51it/s]\n",
      "\n",
      " 52%|███████████████████▎                 | 2310144/4422102 [00:16<00:15, 132719.39it/s]\n",
      "\n",
      " 53%|████████████████████▎                 | 2359296/4422102 [00:17<00:24, 83346.44it/s]\n",
      "32768it [00:22, 42025.33it/s]                                                           \n",
      "\n",
      " 54%|████████████████████▍                 | 2375680/4422102 [00:19<01:33, 21851.74it/s]\n",
      "\n",
      " 55%|████████████████████▊                 | 2416640/4422102 [00:20<01:10, 28520.76it/s]\n",
      "\n",
      " 55%|████████████████████▉                 | 2433024/4422102 [00:20<01:02, 31869.93it/s]\n",
      "\n",
      " 55%|████████████████████▉                 | 2441216/4422102 [00:21<01:00, 32710.63it/s]\n",
      "\n",
      " 56%|█████████████████████                 | 2457600/4422102 [00:21<00:52, 37392.08it/s]\n",
      "\n",
      " 56%|█████████████████████▎                | 2482176/4422102 [00:21<00:39, 49623.99it/s]\n",
      "\n",
      " 57%|█████████████████████▍                | 2498560/4422102 [00:21<00:34, 56034.97it/s]\n",
      "\n",
      " 57%|█████████████████████▊                | 2531328/4422102 [00:21<00:27, 69491.51it/s]\n",
      "\n",
      " 58%|█████████████████████▉                | 2547712/4422102 [00:22<00:26, 71773.88it/s]\n",
      "\n",
      " 58%|██████████████████████▏               | 2580480/4422102 [00:22<00:24, 74477.18it/s]\n",
      "\n",
      " 59%|██████████████████████▌               | 2621440/4422102 [00:22<00:19, 91882.76it/s]\n",
      "\n",
      " 60%|██████████████████████▋               | 2637824/4422102 [00:22<00:20, 88449.12it/s]\n",
      "\n",
      " 60%|██████████████████████▎              | 2662400/4422102 [00:22<00:16, 107060.97it/s]\n",
      "\n",
      " 61%|██████████████████████▌              | 2703360/4422102 [00:23<00:13, 130288.38it/s]\n",
      "\n",
      " 62%|██████████████████████▉              | 2744320/4422102 [00:23<00:13, 126839.66it/s]\n",
      "\n",
      " 63%|███████████████████████▎             | 2785280/4422102 [00:23<00:13, 117335.48it/s]\n",
      "\n",
      " 64%|███████████████████████▋             | 2826240/4422102 [00:24<00:11, 143942.80it/s]\n",
      "\n",
      " 65%|███████████████████████▉             | 2867200/4422102 [00:24<00:10, 143242.06it/s]\n",
      "\n",
      " 66%|████████████████████████▎            | 2908160/4422102 [00:24<00:09, 160123.00it/s]\n",
      "\n",
      " 66%|████████████████████████▌            | 2932736/4422102 [00:24<00:10, 146149.85it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████▋            | 2957312/4422102 [00:24<00:10, 137202.54it/s]\n",
      "\n",
      " 68%|█████████████████████████            | 2998272/4422102 [00:25<00:09, 152047.09it/s]\n",
      "\n",
      " 68%|█████████████████████████▎           | 3022848/4422102 [00:25<00:09, 140587.19it/s]\n",
      "\n",
      " 69%|█████████████████████████▍           | 3039232/4422102 [00:25<00:11, 115288.24it/s]\n",
      "\n",
      " 69%|█████████████████████████▌           | 3055616/4422102 [00:25<00:12, 107537.41it/s]\n",
      "\n",
      " 70%|█████████████████████████▊           | 3080192/4422102 [00:25<00:12, 106365.24it/s]\n",
      "\n",
      " 71%|██████████████████████████▏          | 3129344/4422102 [00:26<00:11, 115156.04it/s]\n",
      "\n",
      " 72%|██████████████████████████▌          | 3178496/4422102 [00:26<00:09, 129218.83it/s]\n",
      "\n",
      " 73%|██████████████████████████▉          | 3219456/4422102 [00:26<00:08, 144723.59it/s]\n",
      "\n",
      " 74%|███████████████████████████▎         | 3260416/4422102 [00:26<00:07, 157828.35it/s]\n",
      "\n",
      " 75%|███████████████████████████▌         | 3301376/4422102 [00:27<00:06, 168130.78it/s]\n",
      "\n",
      " 76%|███████████████████████████▉         | 3342336/4422102 [00:27<00:06, 177644.51it/s]\n",
      "\n",
      " 77%|████████████████████████████▎        | 3383296/4422102 [00:27<00:07, 144531.49it/s]\n",
      "\n",
      " 77%|████████████████████████████▋        | 3424256/4422102 [00:27<00:06, 157291.14it/s]\n",
      "\n",
      " 78%|████████████████████████████▉        | 3457024/4422102 [00:28<00:06, 158056.02it/s]\n",
      "\n",
      " 79%|█████████████████████████████▏       | 3481600/4422102 [00:28<00:05, 171091.62it/s]\n",
      "\n",
      " 79%|█████████████████████████████▎       | 3506176/4422102 [00:28<00:05, 160451.50it/s]\n",
      "\n",
      " 80%|█████████████████████████████▌       | 3538944/4422102 [00:28<00:04, 184347.47it/s]\n",
      "\n",
      " 81%|█████████████████████████████▉       | 3579904/4422102 [00:28<00:04, 184894.74it/s]\n",
      "\n",
      " 82%|██████████████████████████████▎      | 3620864/4422102 [00:28<00:04, 193753.05it/s]\n",
      "\n",
      " 82%|██████████████████████████████▌      | 3645440/4422102 [00:29<00:04, 166413.42it/s]\n",
      "\n",
      " 83%|██████████████████████████████▋      | 3670016/4422102 [00:29<00:05, 146629.57it/s]\n",
      "\n",
      " 84%|███████████████████████████████      | 3710976/4422102 [00:29<00:04, 160313.09it/s]\n",
      "\n",
      " 85%|███████████████████████████████▍     | 3751936/4422102 [00:29<00:03, 170542.28it/s]\n",
      "\n",
      " 85%|███████████████████████████████▌     | 3776512/4422102 [00:29<00:03, 173316.59it/s]\n",
      "\n",
      " 86%|███████████████████████████████▉     | 3817472/4422102 [00:30<00:03, 166549.93it/s]\n",
      "\n",
      " 87%|████████████████████████████████▏    | 3842048/4422102 [00:30<00:03, 183792.19it/s]\n",
      "\n",
      " 87%|████████████████████████████████▎    | 3866624/4422102 [00:30<00:02, 197902.54it/s]\n",
      "\n",
      " 88%|████████████████████████████████▌    | 3891200/4422102 [00:30<00:02, 192524.49it/s]\n",
      "\n",
      " 89%|████████████████████████████████▊    | 3915776/4422102 [00:30<00:02, 179741.46it/s]\n",
      "\n",
      " 89%|████████████████████████████████▉    | 3940352/4422102 [00:30<00:02, 187776.80it/s]\n",
      "\n",
      " 90%|█████████████████████████████████▏   | 3964928/4422102 [00:31<00:02, 161578.78it/s]\n",
      "\n",
      " 91%|█████████████████████████████████▌   | 4005888/4422102 [00:31<00:02, 186951.70it/s]\n",
      "\n",
      " 92%|█████████████████████████████████▊   | 4046848/4422102 [00:31<00:02, 175652.10it/s]\n",
      "\n",
      " 92%|██████████████████████████████████▏  | 4087808/4422102 [00:31<00:02, 143488.24it/s]\n",
      "\n",
      " 93%|██████████████████████████████████▌  | 4128768/4422102 [00:31<00:01, 165969.85it/s]\n",
      "\n",
      " 94%|██████████████████████████████████▉  | 4177920/4422102 [00:32<00:01, 173942.63it/s]\n",
      "\n",
      " 95%|███████████████████████████████████▎ | 4218880/4422102 [00:32<00:01, 180681.14it/s]\n",
      "\n",
      " 96%|███████████████████████████████████▋ | 4259840/4422102 [00:32<00:01, 145400.62it/s]\n",
      "\n",
      " 97%|███████████████████████████████████▉ | 4300800/4422102 [00:33<00:00, 158223.62it/s]\n",
      "\n",
      " 98%|████████████████████████████████████▎| 4341760/4422102 [00:33<00:00, 169563.69it/s]\n",
      "\n",
      " 99%|████████████████████████████████████▋| 4382720/4422102 [00:33<00:00, 177721.15it/s]\n",
      "\n",
      "100%|████████████████████████████████████▉| 4407296/4422102 [00:33<00:00, 154991.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "\n",
      "\n",
      "  0%|                                                          | 0/5148 [00:02<?, ?it/s]\n",
      "\n",
      "\n",
      "8192it [00:02, 3396.28it/s]                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to C:\\Users\\sgoswami/.pytorch/F_MNIST_data/FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4423680it [00:49, 154991.44it/s]                                                        "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import helper\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "imgs = images.view(images.shape[0],-1)\n",
    "print(imgs.shape)\n",
    "helper.imshow(image[4,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Here you should define your network. As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. You should include at least one hidden layer. We suggest you use ReLU activations for the layers and to return the logits or log-softmax from the forward pass. It's up to you how many layers you add and the size of those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your network architecture here\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128,64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64,10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Now you should create your network and train it. First you'll want to define [the criterion](http://pytorch.org/docs/master/nn.html#loss-functions) ( something like `nn.CrossEntropyLoss`) and [the optimizer](http://pytorch.org/docs/master/optim.html) (typically `optim.SGD` or `optim.Adam`).\n",
    "\n",
    "Then write the training code. Remember the training pass is a fairly straightforward process:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "By adjusting the hyperparameters (hidden units, learning rate, etc), you should be able to get the training loss below 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the network, define the criterion and optimizer\n",
    "citerion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968.901857405901\n",
      "527.0633297562599\n",
      "463.15053355693817\n",
      "428.51440869271755\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train the network here\n",
    "epoch = 5\n",
    "runningLoss = 0\n",
    "for n in range(epoch):\n",
    "    runningLoss = 0\n",
    "    for images,labels in trainloader:\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(images)\n",
    "        loss = citerion(predictions,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()s\n",
    "    print(runningLoss)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "\n",
    "# Test out your network!\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.resize_(1, 784)\n",
    "\n",
    "# TODO: Calculate the class probabilities (softmax) for img\n",
    "logps = model(img)\n",
    "ps = torch.exp(logps)\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
